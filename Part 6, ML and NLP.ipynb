{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfa3dab-13c7-4836-97b1-98ae7f1384ef",
   "metadata": {},
   "source": [
    "# Part 6 Machine Learning and Deep NLP\n",
    "\n",
    "*Christina Brockway*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95dd63-db87-4ae3-bf5d-c22f7d4461ff",
   "metadata": {},
   "source": [
    "### Tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693eb7e-dfa4-45cb-bf2c-c1bbaa9c1d33",
   "metadata": {},
   "source": [
    "**Machine Learning Model**\n",
    "-  Drop any reviews that don't have a rating\n",
    "-  Use original review column as X and classification as y\n",
    "-  Use modeling pipelines with text vectorizer and model in same pipeline\n",
    "    -  Select a sklearn vectorizer\n",
    "    -  Select a Classificatation model\n",
    "-  Fit and evaluate the model\n",
    "-  Document observations from results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ce22d-db8e-4627-98c0-618585b3aeff",
   "metadata": {},
   "source": [
    "**Improve Model GridSearch Text Vectorization**\n",
    "-  Construct a grid of parameters\n",
    "-  Fit and evaluate grid search results\n",
    "-  Document:\n",
    "    -  What were best parameters?\n",
    "    -  How does the best estimator perform? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051d1b4-b220-4b55-8094-c2b0895b38a5",
   "metadata": {},
   "source": [
    "**Deep NLP (RNN)**\n",
    "-  Create train/test/validation datasets\n",
    "    -  Convert target categories to integers using LabelEncoder\n",
    "    -  Create tensorflow dataset using X and y\n",
    "    -  Split data\n",
    "-  Create Keras Text Vectorization Layer\n",
    "    -  Create Keras Text Vectorization layer for RNN model\n",
    "    -  Fit/Adapt on training text\n",
    "    -  Save Vocabulary size to use in embedding layer\n",
    "-  Build RNN\n",
    "-  Fit and Evaluate the model\n",
    "-  Document observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5cf73-62b0-4c03-b744-a1d36dbd3246",
   "metadata": {},
   "source": [
    "#### Load Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a520f344-fa23-4991-9e5e-c9f3d463ee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Unidecode\n",
      "  Obtaining dependency information for Unidecode from https://files.pythonhosted.org/packages/84/b7/6ec57841fb67c98f52fc8e4a2d96df60059637cba077edc569a302a8ffc7/Unidecode-1.3.8-py3-none-any.whl.metadata\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "   ---------------------------------------- 0.0/235.5 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 81.9/235.5 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 235.5/235.5 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: Unidecode\n",
      "Successfully installed Unidecode-1.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53eacbfe-78d1-40f1-ba3f-3204dc977079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_colwidth',300)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import TweetTokenizer\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import joblib\n",
    "import my_functions as mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "894953c3-ccc5-4cbf-b70a-fd6c99043c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Check sys.path for python path\n",
    "sys.path\n",
    "#Get the absolute file path of parent directory\n",
    "os.path.abspath('../')\n",
    "#Add parent directory to python path\n",
    "sys.path.append( os.path.abspath('../'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a29ab606-d547-47fa-bf9f-998a7193e076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>html</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>tokens-joined</th>\n",
       "      <th>lemmas-joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a guilty pleasure for me personally, as i love...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "      <td>[guilty, pleasure, personally, love, great, es...</td>\n",
       "      <td>[guilty, pleasure, personally, love, great, es...</td>\n",
       "      <td>guilty pleasure personally love great escape w...</td>\n",
       "      <td>guilty pleasure personally love great escape w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating html  length  \\\n",
       "1  a guilty pleasure for me personally, as i love...     9.0  NaN     251   \n",
       "\n",
       "                                              tokens  \\\n",
       "1  [guilty, pleasure, personally, love, great, es...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "1  [guilty, pleasure, personally, love, great, es...   \n",
       "\n",
       "                                       tokens-joined  \\\n",
       "1  guilty pleasure personally love great escape w...   \n",
       "\n",
       "                                       lemmas-joined  \n",
       "1  guilty pleasure personally love great escape w...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = joblib.load('data-NLP/processed_data.joblib')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ce7c53-e40f-47cc-81e7-4bd9ae65221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2422 entries, 1 to 8647\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   review         2422 non-null   object \n",
      " 1   rating         2422 non-null   float64\n",
      " 2   html           160 non-null    object \n",
      " 3   length         2422 non-null   int64  \n",
      " 4   tokens         2422 non-null   object \n",
      " 5   lemmas         2422 non-null   object \n",
      " 6   tokens-joined  2422 non-null   object \n",
      " 7   lemmas-joined  2422 non-null   object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 170.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ebe31d-e3b6-407d-b5f4-2044509be5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2422 entries, 1 to 8647\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   review  2422 non-null   object \n",
      " 1   rating  2422 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 121.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#drop reviews without a rating and irrelevent columns\n",
    "#There are no rows without ratings\n",
    "df=df.drop(columns=(['html', 'length','tokens','lemmas','tokens-joined','lemmas-joined']))\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d202e113-e7db-4791-8cdb-9f45d96422c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into high and low reviews\n",
    "dff = df.copy()\n",
    "def rating_groups(x):\n",
    "    if x>=8.5:\n",
    "        return \"high\"\n",
    "    elif x <=4.0:\n",
    "        return \"low\"\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6751541d-a90d-4627-9540-d892d5318518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     1223\n",
       "high    1199\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['label'] = df['rating'].map(rating_groups)\n",
    "dff['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72ebd9eb-6fce-4b8a-8a42-f8d6e0a4b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a guilty pleasure for me personally, as i love...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the first underwhelmed me, but this one straig...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating label\n",
       "1  a guilty pleasure for me personally, as i love...     9.0  high\n",
       "6  the first underwhelmed me, but this one straig...     3.0   low"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3febfee-86d7-4b64-9699-de45a7a3bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=dff.drop(columns=('rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f877e9d7-3880-4146-80df-3c8733604702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high    0.503855\n",
       "low     0.496145\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define X and y\n",
    "X=dff['review']\n",
    "y=dff['label']\n",
    "\n",
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, random_state=42)\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c2e9827-b528-4191-ba91-d306905fadc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dabaf96-e187-465f-8888-43e7b968f8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1816"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1057a273-1b79-444e-89f0-13da90f7c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline\n",
    "\n",
    "# Select a sklearn vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True, stop_words ='english')\n",
    "\n",
    "#Use RandomForestClassifier\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfc_pipe = Pipeline([('vectorizer', tfidf_vectorizer), ('classifier', rfc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "666b9cea-9c0a-4ebe-81a3-9a909a92f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(stop_words='english')),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f785b871-e74b-48f1-ab82-4b506db86153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "- Evaluating Network...\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'as_numpy_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28224\\843435236.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_classification_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\DataEnrichment\\GitHub\\MySQL-Database-on-Movies\\my_functions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(model, X_train, y_train, X_test, y_test, history, history_figsize, figsize, normalize, output_dict, cmap_train, cmap_test, values_format, colorbar)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m## Check if X_train is a dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'map'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;31m# If it IS a Datset:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# extract y_train and y_train_pred with helper function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_true_pred_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Get predictions for training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\DataEnrichment\\GitHub\\MySQL-Database-on-Movies\\my_functions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(model, ds)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0my_pred_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;31m# Loop through the dataset as a numpy iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;31m# Get prediction with batch_size=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0my_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5898\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5899\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5900\u001b[0m         ):\n\u001b[0;32m   5901\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5902\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'as_numpy_iterator'"
     ]
    }
   ],
   "source": [
    "mf.evaluate_classification_network(rfc_pipe, X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d8dd6b-cbb1-4438-95a6-c3897d28cac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d942767-269f-42e3-b340-f60838decdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa80bf-75d0-4848-809c-dc7034fefffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce395611-6cd6-4315-81ac-2817d98dfdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb02ba-0e6c-4d00-b7a1-05e7740da1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4574b3-6d65-4d94-a2c3-3c53bdff5416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1c835-96b8-401e-9a42-d95fa7e044b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
